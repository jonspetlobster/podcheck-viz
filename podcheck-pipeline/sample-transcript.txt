All-In Podcast Episode 213 - "DeepSeek Shakes Silicon Valley, TikTok Deal Update, Federal Spending Cuts"
Recorded: January 2025

[00:00:00] Jason Calacanis: Welcome everybody to the All-In Podcast. With me today, the Sultan of Science, Chamath Palihapitiya, the Rain Man himself David Friedberg, and of course David Sacks. Boys, we have a massive show today. Let's start with the biggest story in tech right now — DeepSeek. Chamath, what just happened?

[00:00:22] Chamath Palihapitiya: So DeepSeek, which is a Chinese AI lab, released their R1 model, and it essentially matches GPT-4 level performance on most benchmarks. But here's the kicker — they claim they trained it for approximately five point five million dollars. That is two orders of magnitude less than what OpenAI and Google and Anthropic are spending. We're talking about companies that have raised or committed over three hundred billion dollars in capital expenditure for AI infrastructure, and a Chinese lab comes along and does it for the cost of a nice house in Palo Alto.

[00:01:05] David Sacks: I think this is actually the most important development in AI since ChatGPT launched. The market clearly agrees — NVIDIA lost almost six hundred billion dollars in market cap in a single day. That's the largest single-day loss for any company in stock market history. And the reason is simple: if you can train frontier models for five million instead of five hundred million, the entire thesis around massive GPU buildouts comes into question.

[00:01:38] Jason Calacanis: Friedberg, you've been studying the technical details. How did they actually pull this off?

[00:01:44] David Friedberg: There are a few key innovations. First, they used a technique called mixture of experts, or MoE, which means only a fraction of the model's parameters are active for any given query. Second, they did extensive work on quantization — reducing the precision of the model weights from thirty-two bit floating point down to eight bit or even four bit in some cases. Third, and this is the controversial part, there's strong evidence they used distillation from existing frontier models. Essentially, they may have used outputs from GPT-4 and Claude to train their model, which if true, raises significant intellectual property questions.

[00:02:30] Chamath Palihapitiya: Let me push back on the cost number though. The five point five million dollar figure is almost certainly just the final training run. It doesn't include the years of research, the failed experiments, the compute used for distillation, or the fact that they had access to thousands of NVIDIA A100 GPUs before the export ban went into effect. The real cost is probably ten to twenty times higher. But even at a hundred million, it's still dramatically cheaper than what American companies are spending.

[00:03:08] David Sacks: Right, and I think the policy implications here are enormous. We spent the last two years implementing chip export controls to China, and the result is that Chinese researchers were forced to be more efficient. They innovated around the constraints. This is basically the Jevons paradox playing out in real time — when you make something more efficient, you don't use less of it, you use more. The demand for AI compute is going to go up, not down, because of DeepSeek.

[00:03:42] Jason Calacanis: Okay, let me throw out some numbers here. According to the IEA, global data center electricity consumption hit about four hundred sixty terawatt hours in 2024, which is roughly two percent of global electricity demand. Goldman Sachs projects that AI alone will drive data center power consumption to around one thousand terawatt hours by 2030. Chamath, does DeepSeek change that projection?

[00:04:15] Chamath Palihapitiya: No, and this is the key insight that the market got wrong in its initial panic. More efficient models means more deployment, more use cases, more inference. The inference cost matters way more than the training cost because you train once but you run inference billions of times. DeepSeek's efficiency improvements actually accelerate the total compute demand curve. NVIDIA's selloff was overdone — they'll sell just as many GPUs, probably more, because the addressable market for AI just got bigger.

[00:04:52] Jason Calacanis: Let's move to our second topic. The TikTok situation. Sacks, you're now inside the administration as the AI and crypto czar. What can you tell us about the TikTok deal?

[00:05:05] David Sacks: So the Supreme Court upheld the ban, as we know. The administration has given ByteDance an extension — they have seventy-five days from January nineteenth to complete a divestiture. There are multiple bidder groups. The leading contenders include a group led by Frank McCourt with backing from several tech investors, and there's also interest from Oracle and others. The key sticking point is the algorithm. ByteDance doesn't want to sell the recommendation algorithm, but the US government's position is that any deal must include full separation of the algorithm from Chinese control.

[00:05:48] David Friedberg: Can I throw a number out? TikTok generated approximately sixteen billion dollars in US revenue in 2024. Their global revenue was around eighty billion. So the US is roughly twenty percent of their total business. The valuation that's been floated for TikTok US is somewhere between forty and sixty billion dollars, which at three to four times revenue actually isn't crazy for a social media platform growing at thirty percent year over year.

[00:06:22] Jason Calacanis: Chamath, what's your take on the deal structure?

[00:06:25] Chamath Palihapitiya: I think the most likely outcome is a joint venture structure where a US entity owns a controlling stake — probably sixty percent or more — and ByteDance retains a minority economic interest but has zero operational control. The algorithm will be maintained by the US entity, probably running on Oracle's cloud infrastructure. And the US government will have audit rights. The deal probably gets done at around fifty billion dollar valuation, which implies ByteDance walks away with maybe twenty billion for their minority stake. That's a massive haircut from the two hundred billion they were valued at privately.

[00:07:05] Jason Calacanis: Okay, big topic number three. Federal spending cuts. The new Department of Government Efficiency, or DOGE, led by Elon Musk. Sacks, give us the update.

[00:07:18] David Sacks: So DOGE has been extremely active in the first few weeks. They've identified what they claim is over one hundred billion dollars in annual savings across the federal government. Some of the big line items: they've proposed cutting seventy-five percent of USAID's budget, which is about thirty-five billion dollars. They've frozen new hiring across most agencies. They're renegotiating IT contracts — the federal government spends over a hundred billion a year on IT, and a lot of those contracts haven't been competitively bid in years.

[00:07:55] David Friedberg: I want to fact-check one thing here. The total federal budget for fiscal year 2025 is about six point seven trillion dollars. Mandatory spending — Social Security, Medicare, Medicaid, and interest on the debt — accounts for roughly seventy-two percent of that, or about four point eight trillion. So the discretionary budget that DOGE can actually touch is about one point nine trillion. Finding a hundred billion in savings there is meaningful — that's about five percent — but it's not going to solve the deficit, which is projected at one point eight trillion for this fiscal year.

[00:08:38] Chamath Palihapitiya: But here's where it gets interesting. The federal government employs about two point two million civilian workers. Average total compensation is somewhere around one hundred thirty thousand when you include benefits and pension obligations. That's roughly two hundred eighty-five billion dollars in total personnel costs. If DOGE can reduce the workforce by even fifteen to twenty percent through attrition and early retirement offers, you're talking about forty to fifty billion in annual savings. That's real money.

[00:09:15] Jason Calacanis: But won't cutting government workers hurt the economy? I mean, the DC metro area has one of the highest per-capita incomes in the country, largely because of government employment.

[00:09:28] David Sacks: The Washington DC metro area has a median household income of about a hundred and ten thousand dollars, compared to the national median of roughly seventy-five thousand. A lot of that premium is indeed driven by government and government-adjacent jobs. But here's the thing — that's actually part of the problem. We've created this situation where a huge amount of economic activity is concentrated around redistributing tax dollars rather than creating new value. The empirical evidence from countries that have done similar reforms — like New Zealand in the 1980s and Canada in the 1990s — shows that after an initial adjustment period of twelve to eighteen months, the economy actually grows faster because resources are allocated more efficiently.

[00:10:12] David Friedberg: I want to add some context on the USAID cuts specifically. The United States spent about sixty-eight billion dollars on foreign aid in 2024. USAID administered roughly half of that. Now, there are legitimate criticisms about the efficiency of foreign aid — multiple studies, including a comprehensive review published in the Journal of Economic Literature, found that the correlation between foreign aid and GDP growth in recipient countries is essentially zero over the long run. However, targeted health interventions like PEPFAR — the President's Emergency Plan for AIDS Relief — have been remarkably effective. PEPFAR has been credited with saving over twenty-five million lives since 2003, at a cost of about a hundred ten billion total over two decades. That works out to roughly four thousand four hundred dollars per life saved, which is extraordinarily cost-effective by any measure.

[00:11:05] Chamath Palihapitiya: And this is where the cuts need to be surgical rather than indiscriminate. You can't just take a meat cleaver to the entire foreign aid budget. PEPFAR is probably the single greatest humanitarian achievement of the US government in the twenty-first century. But at the same time, there are programs where we're spending hundreds of millions of dollars with very little measurable impact. The GAO — the Government Accountability Office — identified over two hundred billion dollars in improper payments across the federal government in fiscal year 2023. That's money that was literally sent to the wrong people, for the wrong amounts, or for programs people didn't qualify for.

[00:11:48] Jason Calacanis: Let me ask about the macro picture. Friedberg, the national debt just crossed thirty-six trillion dollars. Annual interest payments are now over one trillion, surpassing defense spending for the first time ever. Is this sustainable?

[00:12:05] David Friedberg: The short answer is no, not on the current trajectory. The Congressional Budget Office projects that the debt-to-GDP ratio will hit one hundred sixteen percent by 2034, up from about ninety-seven percent today. For context, the historical average is about forty-five percent. Interest payments are currently about three point two percent of GDP and rising. When they get above four percent, which CBO projects will happen around 2030, you start getting into territory where the interest expense alone begins to crowd out other government spending. Japan has managed a debt-to-GDP ratio of over two hundred fifty percent, but they have structural advantages — a high domestic savings rate, a current account surplus, and most of their debt is held domestically. The US doesn't have those advantages. About thirty percent of US treasuries are held by foreign entities.

[00:13:02] David Sacks: This is why growth is so important. If you can get GDP growth from the current trend of about two percent up to three or three and a half percent, the math changes dramatically. A one percentage point increase in GDP growth generates roughly three hundred billion in additional tax revenue annually without raising rates. That's almost enough to close the deficit by itself. And I think that's the real bet the administration is making — that deregulation plus AI-driven productivity gains plus energy independence can push growth above three percent sustainably.

[00:13:42] Jason Calacanis: Alright, let's do a quick science corner. Friedberg, you've got something on nuclear fusion?

[00:13:48] David Friedberg: Yeah, so Commonwealth Fusion Systems announced that their SPARC tokamak reactor is on track for a net energy demonstration by 2027. This would be the first commercially-relevant fusion reactor to produce more energy than it consumes. They're using high-temperature superconducting magnets — specifically rare earth barium copper oxide tape — which allows them to build a much smaller and cheaper reactor than previous designs. Their magnets achieved a field strength of twenty tesla, which is roughly twice what ITER's magnets can achieve. The total project cost for SPARC is about two billion dollars, compared to ITER's estimated twenty-two billion and counting.

[00:14:35] Chamath Palihapitiya: And Google just invested five hundred million into Commonwealth's latest round, which valued them at about twelve billion dollars. The fusion industry as a whole has attracted over six billion in private investment. My take is that if fusion works — and the physics says it should — it would be the most transformative energy technology since the steam engine. A single fusion plant could produce about a gigawatt of clean baseload power. You'd need roughly five thousand of them to power the entire world. At two billion per plant, that's ten trillion dollars — sounds like a lot, but it's comparable to what we spend on fossil fuel infrastructure every decade anyway.

[00:15:18] Jason Calacanis: That's an incredible breakdown. Alright boys, let's wrap it there. For the All-In Podcast, I'm Jason Calacanis. We'll see you next time.
